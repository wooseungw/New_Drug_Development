{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "labeled_data_csv = \"./data/finger_maccs_fp_train.csv\"  # 레이블이 있는 데이터 파일\n",
    "unlabeled_data_csv = \"./data/unlabeled_maccs.csv\"  # 레이블이 없는 데이터 파일\n",
    "\n",
    "# CSV 파일 읽기\n",
    "labeled_data = pd.read_csv(labeled_data_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "unlabeled_data = pd.read_csv(unlabeled_data_csv).drop(columns=[\"SMILES\", 'Unnamed: 0'])\n",
    "\n",
    "labeled_data = labeled_data.fillna(0)\n",
    "unlabeled_data = unlabeled_data.fillna(0)\n",
    "\n",
    "# 변환을 원하는 열의 이름(컬럼명)을 리스트로 지정\n",
    "columns_to_convert = [str(i) for i in range(167)]\n",
    "\n",
    "\n",
    "# columns_to_convert에 있는 열에 대해 0과 1로 된 이진 데이터를 10진수로 변환\n",
    "\n",
    "labeled_data['decimal'] = labeled_data[columns_to_convert].apply(lambda row: int(''.join(map(str, row)), 2), axis=1)\n",
    "# StandardScaler 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 'decimal' 열에 대해 Z-Score 정규화 적용\n",
    "labeled_data['decimal'] = scaler.fit_transform(labeled_data[['decimal']])\n",
    "labeled_data['decimal'] = labeled_data['decimal'].astype(int)\n",
    "\n",
    "# 계산에 사용된 열들을 삭제\n",
    "labeled_data.drop(columns=columns_to_convert, inplace=True)\n",
    "\n",
    "\n",
    "# columns_to_convert에 있는 열에 대해 0과 1로 된 이진 데이터를 10진수로 변환\n",
    "\n",
    "unlabeled_data['decimal'] = unlabeled_data[columns_to_convert].apply(lambda row: int(''.join(map(str, row)), 2), axis=1)\n",
    "# StandardScaler 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 'decimal' 열에 대해 Z-Score 정규화 적용\n",
    "unlabeled_data['decimal'] = scaler.fit_transform(unlabeled_data[['decimal']])\n",
    "unlabeled_data['decimal'] = unlabeled_data['decimal'].astype(int)\n",
    "\n",
    "# 계산에 사용된 열들을 삭제\n",
    "unlabeled_data.drop(columns=columns_to_convert, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8533mhpi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>33.31671</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-pyramid-27</strong> at: <a href='https://wandb.ai/limbw/New_drug/runs/8533mhpi' target=\"_blank\">https://wandb.ai/limbw/New_drug/runs/8533mhpi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230920_232920-8533mhpi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8533mhpi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/MMI24limbyungwan/New_Drug_Development/wandb/run-20230920_233029-e9m90k9n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/limbw/New_drug/runs/e9m90k9n' target=\"_blank\">genial-sound-28</a></strong> to <a href='https://wandb.ai/limbw/New_drug' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/limbw/New_drug' target=\"_blank\">https://wandb.ai/limbw/New_drug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/limbw/New_drug/runs/e9m90k9n' target=\"_blank\">https://wandb.ai/limbw/New_drug/runs/e9m90k9n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:18<00:00,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 35.82967655888267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▂▁▄▁▂▃█▃▁▂▂▃█▆▇▆▄▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>33.78592</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-sound-28</strong> at: <a href='https://wandb.ai/limbw/New_drug/runs/e9m90k9n' target=\"_blank\">https://wandb.ai/limbw/New_drug/runs/e9m90k9n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230920_233029-e9m90k9n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Active Learning 반복 과정\n",
    "n_queries = 20\n",
    "batch_size = 1750  # 각 반복에서 선택할 배치 크기\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"New_drug\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": n_queries,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# CSV 파일 경로\n",
    "# labeled_data_csv = \"./origin_data/train.csv\"  # 레이블이 있는 데이터 파일\n",
    "# unlabeled_data_csv = \"./data/unlabeld_data2.csv\"  # 레이블이 없는 데이터 파일\n",
    "##\n",
    "# labeled_data_csv = \"./data/finger_maccs_fp_train.csv\"  # 레이블이 있는 데이터 파일\n",
    "# unlabeled_data_csv = \"./data/unlabeled_maccs.csv\"  # 레이블이 없는 데이터 파일\n",
    "\n",
    "# # CSV 파일 읽기\n",
    "# labeled_data = pd.read_csv(labeled_data_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "# unlabeled_data = pd.read_csv(unlabeled_data_csv).drop(columns=[\"SMILES\", 'Unnamed: 0'])\n",
    "\n",
    "# labeled_data = labeled_data.fillna(0)\n",
    "# unlabeled_data = unlabeled_data.fillna(0)\n",
    "\n",
    "\n",
    "# 레이블이 있는 데이터 추출\n",
    "X_labeled = labeled_data.drop(columns=['MLM', 'HLM'])\n",
    "Y_labeled = labeled_data[['MLM', 'HLM']]\n",
    "label = ['MLM', 'HLM']\n",
    "###\n",
    "# # 초기 학습 데이터 선택 (랜덤으로 선택)\n",
    "# initial_idx = np.random.choice(range(len(X_labeled)), size=1000, replace=False)\n",
    "# X_initial = X_labeled.iloc[initial_idx]\n",
    "# Y_initial = Y_labeled.iloc[initial_idx]\n",
    "\n",
    "# 초기 학습 데이터 선택 (80%)\n",
    "test_size = 0.2  # 전체 데이터 중 테스트 데이터 비율 (예: 20%)\n",
    "X_initial, X_test, Y_initial, Y_test = train_test_split(X_labeled, Y_labeled, test_size=test_size, random_state=42)\n",
    "X_test1, X_test2, Y_test1, Y_test2 = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
    "###\n",
    "\n",
    "# 초기 모델 학습 (랜덤 포레스트 회귀 모델 사용)\n",
    "initial_model = RandomForestRegressor()\n",
    "#initial_model = xgb.XGBRegressor(tree_method = 'hist', gpu_id = 0)\n",
    "initial_model.fit(X_initial, Y_initial)\n",
    "\n",
    "for i in tqdm(range(n_queries)):\n",
    "    # 예측 오차를 계산하여 불확실성을 측정\n",
    "    Y_pred = initial_model.predict(unlabeled_data)  # 레이블이 없는 데이터에 대한 예측\n",
    "    #uncertainty = np.abs(Y_pred - np.mean(Y_pred, axis=0))\n",
    "    uncertainty = 1 - np.max(Y_pred, axis=1)\n",
    "\n",
    "    # 불확실성이 가장 큰 상위 배치 크기만큼 데이터 포인트 선택\n",
    "    #query_indices = np.argsort(uncertainty.sum(axis=1))[-batch_size:]\n",
    "    query_indices = np.argsort(uncertainty)[-batch_size:]\n",
    "\n",
    "    for query_idx in query_indices:\n",
    "        # 쿼리된 데이터는 학습 데이터에 추가\n",
    "        X_query = unlabeled_data.iloc[query_idx:query_idx+1]\n",
    "        Y_query = Y_pred[query_idx:query_idx+1]  # 모델 예측값을 사용\n",
    "\n",
    "        X_initial = pd.concat([X_initial, X_query])\n",
    "        Y_initial = np.vstack([Y_initial, Y_query])\n",
    "\n",
    "    # 쿼리된 데이터는 레이블이 없는 데이터에서 제거 (선택된 데이터만큼 제거)\n",
    "    unlabeled_data = unlabeled_data.drop(unlabeled_data.index[query_indices])\n",
    "\n",
    "    # 새로운 모델을 학습하여 계속 진행\n",
    "    initial_model = RandomForestRegressor()\n",
    "    #initial_model = xgb.XGBRegressor(tree_method = 'hist', gpu_id = 0)\n",
    "    initial_model.fit(X_initial, Y_initial)\n",
    "\n",
    "    Y_pred = initial_model.predict(X_test1)\n",
    "\n",
    "    rmse_MLM = np.sqrt(mean_squared_error(Y_test1[\"MLM\"], Y_pred[:,0]))\n",
    "    rmse_HLM = np.sqrt(mean_squared_error(Y_test1[\"HLM\"], Y_pred[:,1]))\n",
    "    loss = (rmse_HLM+rmse_MLM)/2\n",
    "        # log metrics to wandb\n",
    "    wandb.log({\"loss\": loss})\n",
    "\n",
    "\n",
    "Y_pred = initial_model.predict(X_test2)\n",
    "\n",
    "rmse_MLM = np.sqrt(mean_squared_error(Y_test2[\"MLM\"], Y_pred[:,0]))\n",
    "rmse_HLM = np.sqrt(mean_squared_error(Y_test2[\"HLM\"], Y_pred[:,1]))\n",
    "rmse = (rmse_HLM+rmse_MLM)/2\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:520: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(data):\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "c:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (2799) does not match length of index (2798)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Workspace\\New_Drug_Development\\Semi-supervised_LBW.ipynb 셀 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Workspace/New_Drug_Development/Semi-supervised_LBW.ipynb#X10sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     X_initial \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([X_initial, X_query])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Workspace/New_Drug_Development/Semi-supervised_LBW.ipynb#X10sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39m# MLM 및 HLM에 대한 레이블 추가\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Workspace/New_Drug_Development/Semi-supervised_LBW.ipynb#X10sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     Y_initial[\u001b[39m\"\u001b[39;49m\u001b[39mMLM\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(Y_initial[\u001b[39m\"\u001b[39m\u001b[39mMLM\u001b[39m\u001b[39m\"\u001b[39m], Y_query_MLM)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Workspace/New_Drug_Development/Semi-supervised_LBW.ipynb#X10sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     Y_initial[\u001b[39m\"\u001b[39m\u001b[39mHLM\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(Y_initial[\u001b[39m\"\u001b[39m\u001b[39mHLM\u001b[39m\u001b[39m\"\u001b[39m], Y_query_HLM)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Workspace/New_Drug_Development/Semi-supervised_LBW.ipynb#X10sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m# 쿼리된 데이터는 레이블이 없는 데이터에서 제거 (선택된 데이터만큼 제거)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\pandas\\core\\frame.py:4094\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4091\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4092\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   4093\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 4094\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\pandas\\core\\frame.py:4303\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4294\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4295\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4296\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4301\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4303\u001b[0m     value, refs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4305\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4306\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4307\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4308\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4309\u001b[0m     ):\n\u001b[0;32m   4310\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4311\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\pandas\\core\\frame.py:5042\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5039\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   5041\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5042\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   5043\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\hong2\\Lib\\site-packages\\pandas\\core\\common.py:561\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    564\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (2799) does not match length of index (2798)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Active Learning 반복 과정\n",
    "n_queries = 20\n",
    "batch_size = 1750  # 각 반복에서 선택할 배치 크기\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"New_drug\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.01,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": n_queries,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# CSV 파일 경로\n",
    "labeled_data_csv = \"./data/finger_maccs_fp_train.csv\"  # 레이블이 있는 데이터 파일\n",
    "unlabeled_data_csv = \"./data/unlabeled_maccs.csv\"  # 레이블이 없는 데이터 파일\n",
    "\n",
    "# CSV 파일 읽기\n",
    "labeled_data = pd.read_csv(labeled_data_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "unlabeled_data = pd.read_csv(unlabeled_data_csv).drop(columns=[\"SMILES\", 'Unnamed: 0'])\n",
    "\n",
    "labeled_data = labeled_data.fillna(0)\n",
    "unlabeled_data = unlabeled_data.fillna(0)\n",
    "\n",
    "# 레이블이 있는 데이터 추출\n",
    "X_labeled = labeled_data.drop(columns=['MLM', 'HLM', 'Unnamed: 0'])\n",
    "Y_labeled = labeled_data[['MLM', 'HLM']]\n",
    "label = ['MLM', 'HLM']\n",
    "\n",
    "# 초기 학습 데이터 선택 (80%)\n",
    "test_size = 0.2  # 전체 데이터 중 테스트 데이터 비율 (예: 20%)\n",
    "X_initial, X_test, Y_initial, Y_test = train_test_split(X_labeled, Y_labeled, test_size=test_size, random_state=42)\n",
    "X_test1, X_test2, Y_test1, Y_test2 = train_test_split(X_test, Y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# 초기 모델 학습 (랜덤 포레스트 회귀 모델 사용)\n",
    "initial_model_MLM = xgb.XGBRegressor(tree_method='hist', gpu_id=0)\n",
    "initial_model_HLM = xgb.XGBRegressor(tree_method='hist', gpu_id=0)\n",
    "initial_model_MLM.fit(X_initial, Y_initial[\"MLM\"])\n",
    "initial_model_HLM.fit(X_initial, Y_initial[\"HLM\"])\n",
    "\n",
    "for i in tqdm(range(n_queries)):\n",
    "    # 예측 오차를 계산하여 불확실성을 측정\n",
    "    Y_pred_MLM = initial_model_MLM.predict(unlabeled_data)  # 레이블이 없는 데이터에 대한 MLM 예측\n",
    "    Y_pred_HLM = initial_model_HLM.predict(unlabeled_data)  # 레이블이 없는 데이터에 대한 HLM 예측\n",
    "\n",
    "    uncertainty_MLM = 1 - np.max(Y_pred_MLM, axis=0)\n",
    "    uncertainty_HLM = 1 - np.max(Y_pred_HLM, axis=0)\n",
    "\n",
    "    # MLM 모델에 대한 불확실성이 가장 큰 상위 배치 크기만큼 데이터 포인트 선택\n",
    "    query_indices_MLM = np.argsort(uncertainty_MLM)[-batch_size:]\n",
    "\n",
    "    # HLM 모델에 대한 불확실성이 가장 큰 상위 배치 크기만큼 데이터 포인트 선택\n",
    "    query_indices_HLM = np.argsort(uncertainty_HLM)[-batch_size:]\n",
    "\n",
    "    for query_idx_MLM, query_idx_HLM in zip(query_indices_MLM, query_indices_HLM):\n",
    "        # 쿼리된 데이터는 학습 데이터에 추가\n",
    "        X_query = unlabeled_data.iloc[query_idx_MLM:query_idx_MLM+1]\n",
    "        Y_query_MLM = Y_pred_MLM[query_idx_MLM:query_idx_MLM+1]\n",
    "        Y_query_HLM = Y_pred_HLM[query_idx_HLM:query_idx_HLM+1]\n",
    "\n",
    "        X_initial = pd.concat([X_initial, X_query])\n",
    "        # MLM 및 HLM에 대한 레이블 추가\n",
    "        Y_initial[\"MLM\"] = np.append(Y_initial[\"MLM\"], Y_query_MLM)\n",
    "        Y_initial[\"HLM\"] = np.append(Y_initial[\"HLM\"], Y_query_HLM)\n",
    "        \n",
    "    # 쿼리된 데이터는 레이블이 없는 데이터에서 제거 (선택된 데이터만큼 제거)\n",
    "    unlabeled_data = unlabeled_data.drop(unlabeled_data.index[query_indices_MLM])\n",
    "\n",
    "    # 새로운 모델을 학습하여 계속 진행\n",
    "    initial_model_MLM = xgb.XGBRegressor(tree_method='hist', gpu_id=0)\n",
    "    initial_model_HLM = xgb.XGBRegressor(tree_method='hist', gpu_id=0)\n",
    "    initial_model_MLM.fit(X_initial, Y_initial[\"MLM\"])\n",
    "    initial_model_HLM.fit(X_initial, Y_initial[\"HLM\"])\n",
    "\n",
    "    # MLM 모델 테스트 및 WandB에 로그 기록\n",
    "    Y_pred_MLM = initial_model_MLM.predict(X_test1)\n",
    "    rmse_MLM = np.sqrt(mean_squared_error(Y_test1[\"MLM\"], Y_pred_MLM))\n",
    "    loss_MLM = rmse_MLM\n",
    "    wandb.log({\"MLM_loss\": loss_MLM})\n",
    "\n",
    "    # HLM 모델 테스트 및 WandB에 로그 기록\n",
    "    Y_pred_HLM = initial_model_HLM.predict(X_test1)\n",
    "    rmse_HLM = np.sqrt(mean_squared_error(Y_test1[\"HLM\"], Y_pred_HLM))\n",
    "    loss_HLM = rmse_HLM\n",
    "    #wandb.log({\"HLM_loss\": loss_HLM})\n",
    "\n",
    "# 최종 테스트 결과 출력\n",
    "Y_pred_MLM = initial_model_MLM.predict(X_test2)\n",
    "rmse_MLM = np.sqrt(mean_squared_error(Y_test2[\"MLM\"], Y_pred_MLM))\n",
    "\n",
    "Y_pred_HLM = initial_model_HLM.predict(X_test2)\n",
    "rmse_HLM = np.sqrt(mean_squared_error(Y_test2[\"HLM\"], Y_pred_HLM))\n",
    "\n",
    "rmse = (rmse_HLM + rmse_MLM) / 2\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "# # [optional] finish the wandb run, necessary in notebooks\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./AutogluonModels/initial_model_maccs_SS.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 모델 저장\n",
    "joblib.dump(initial_model, './AutogluonModels/initial_model_maccs_SS.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# # 모델 로드\n",
    "# loaded_model = joblib.load('initial_model1.pkl')\n",
    "\n",
    "# # 로드한 모델로 예측 등을 수행할 수 있음\n",
    "# loaded_predictions = loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_df = pd.DataFrame(Y_pred)\n",
    "# Y_pred_df.to_csv(\"./data/SS_valid_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_csv = \"./origin_data/test.csv\"\n",
    "test_csv = \"./data/finger_maccs_fp_test.csv\"\n",
    "test_data = pd.read_csv(test_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "test_data = test_data.fillna(0)\n",
    "test_data['decimal'] = test_data[columns_to_convert].apply(lambda row: int(''.join(map(str, row)), 2), axis=1)\n",
    "# StandardScaler 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 'decimal' 열에 대해 Z-Score 정규화 적용\n",
    "test_data['decimal'] = scaler.fit_transform(test_data[['decimal']])\n",
    "test_data['decimal'] = test_data['decimal'].astype(int)\n",
    "\n",
    "# 계산에 사용된 열들을 삭제\n",
    "test_data.drop(columns=columns_to_convert, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test_csv = \"./origin_data/test.csv\"\n",
    "# test_csv = \"./data/finger_maccs_fp_test.csv\"\n",
    "# test_data = pd.read_csv(test_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "# test_data = test_data.fillna(0)\n",
    "\n",
    "Y_test_pred = initial_model.predict(test_data)\n",
    "# predict\n",
    "df_submission = pd.read_csv(\"./origin_data/sample_submission.csv\")\n",
    "df_submission[\"MLM\"] = Y_test_pred[:,0]\n",
    "df_submission[\"HLM\"] = Y_test_pred[:,1]\n",
    "df_submission.to_csv(\"./submission/submission_SSwandb_maccs1_LBW.csv\", index = False, encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "autog = pd.read_csv(\"./submission/autog.csv\")\n",
    "ss2 = pd.read_csv(\"./submission/submission_SS2_LBW.csv\")\n",
    "ss = pd.read_csv(\"./submission/submission_SS_LBW.csv\")\n",
    "ss35 = pd.read_csv(\"./submission/submission_SS35k_LBW.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
