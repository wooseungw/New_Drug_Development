{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from modAL.models import ActiveLearner\n",
    "# from modAL.uncertainty import uncertainty_sampling\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # CSV 파일 경로\n",
    "# labeled_data_csv = \"./origin_data/train.csv\" # 레이블이 있는 데이터 파일\n",
    "# unlabeled_data_csv = \"./data/unlabeld_data.csv\"  # 레이블이 없는 데이터 파일\n",
    "# test_csv = \"./origin_data/test.csv\"\n",
    "\n",
    "# # CSV 파일 읽기\n",
    "# labeled_data = pd.read_csv(labeled_data_csv).drop(columns=[\"LogD\", \"Molecular_PolarSurfaceArea\"])\n",
    "# unlabeled_data = pd.read_csv(unlabeled_data_csv)\n",
    "# test_data = pd.read_csv(test_csv).drop(columns=[\"LogD\", \"Molecular_PolarSurfaceArea\"])\n",
    "\n",
    "# # 레이블이 있는 데이터 추출\n",
    "# X_labeled = labeled_data.drop(columns=['MLM', 'HLM'])\n",
    "# Y_labeled = labeled_data[['MLM', 'HLM']]\n",
    "\n",
    "# # 레이블이 없는 데이터 추출\n",
    "# X_unlabeled = unlabeled_data\n",
    "\n",
    "# # 초기 학습 데이터 선택 (랜덤으로 선택)\n",
    "# initial_idx = np.random.choice(range(len(X_labeled)), size=10, replace=False)\n",
    "# X_initial = X_labeled.iloc[initial_idx]\n",
    "# Y_initial = Y_labeled.iloc[initial_idx]\n",
    "\n",
    "# # 초기 모델 학습\n",
    "# learner = ActiveLearner(\n",
    "#     estimator=RandomForestRegressor(),\n",
    "#     query_strategy=uncertainty_sampling,\n",
    "#     X_training=X_initial,\n",
    "#     y_training=Y_initial\n",
    "# )\n",
    "\n",
    "# # Active Learning 반복 과정\n",
    "# n_queries = 20\n",
    "# for i in range(n_queries):\n",
    "#     query_idx, query_instance = learner.query(X_unlabeled)\n",
    "#     learner.teach(X_unlabeled.iloc[query_idx], Y_unlabeled.iloc[query_idx])\n",
    "    \n",
    "#     # 쿼리된 데이터는 학습 데이터에서 제거\n",
    "#     X_unlabeled = X_unlabeled.drop(X_unlabeled.index[query_idx])\n",
    "#     Y_unlabeled = Y_unlabeled.drop(Y_unlabeled.index[query_idx])\n",
    "\n",
    "# Y_test_pred = learner.predict(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [22:37<00:00, 38.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12.239941547011838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CSV 파일 경로\n",
    "labeled_data_csv = \"./origin_data/train.csv\"  # 레이블이 있는 데이터 파일\n",
    "unlabeled_data_csv = \"./data/unlabeld_data2.csv\"  # 레이블이 없는 데이터 파일\n",
    "\n",
    "\n",
    "# CSV 파일 읽기\n",
    "labeled_data = pd.read_csv(labeled_data_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "unlabeled_data = pd.read_csv(unlabeled_data_csv).drop(columns=[\"SMILES\"])\n",
    "\n",
    "labeled_data = labeled_data.fillna(0)\n",
    "unlabeled_data = unlabeled_data.fillna(0)\n",
    "\n",
    "\n",
    "# 레이블이 있는 데이터 추출\n",
    "X_labeled = labeled_data.drop(columns=['MLM', 'HLM'])\n",
    "Y_labeled = labeled_data[['MLM', 'HLM']]\n",
    "\n",
    "###\n",
    "# # 초기 학습 데이터 선택 (랜덤으로 선택)\n",
    "# initial_idx = np.random.choice(range(len(X_labeled)), size=1000, replace=False)\n",
    "# X_initial = X_labeled.iloc[initial_idx]\n",
    "# Y_initial = Y_labeled.iloc[initial_idx]\n",
    "\n",
    "# 초기 학습 데이터 선택 (80%)\n",
    "test_size = 0.2  # 전체 데이터 중 테스트 데이터 비율 (예: 20%)\n",
    "X_initial, X_test, Y_initial, Y_test = train_test_split(X_labeled, Y_labeled, test_size=test_size, random_state=42)\n",
    "###\n",
    "\n",
    "# 초기 모델 학습 (랜덤 포레스트 회귀 모델 사용)\n",
    "initial_model = RandomForestRegressor()\n",
    "initial_model.fit(X_initial, Y_initial)\n",
    "\n",
    "# Active Learning 반복 과정\n",
    "n_queries = 35\n",
    "batch_size = 1000  # 각 반복에서 선택할 배치 크기\n",
    "\n",
    "for i in tqdm(range(n_queries)):\n",
    "    # 예측 오차를 계산하여 불확실성을 측정\n",
    "    Y_pred = initial_model.predict(unlabeled_data)  # 레이블이 없는 데이터에 대한 예측\n",
    "    #uncertainty = np.abs(Y_pred - np.mean(Y_pred, axis=0))\n",
    "    uncertainty = 1 - np.max(Y_pred, axis=1)\n",
    "\n",
    "    # 불확실성이 가장 큰 상위 배치 크기만큼 데이터 포인트 선택\n",
    "    #query_indices = np.argsort(uncertainty.sum(axis=1))[-batch_size:]\n",
    "    query_indices = np.argsort(uncertainty)[-batch_size:]\n",
    "\n",
    "    for query_idx in query_indices:\n",
    "        # 쿼리된 데이터는 학습 데이터에 추가\n",
    "        X_query = unlabeled_data.iloc[query_idx:query_idx+1]\n",
    "        Y_query = Y_pred[query_idx:query_idx+1]  # 모델 예측값을 사용\n",
    "\n",
    "        X_labeled = pd.concat([X_labeled, X_query])\n",
    "        Y_labeled = np.vstack([Y_labeled, Y_query])\n",
    "\n",
    "    # 쿼리된 데이터는 레이블이 없는 데이터에서 제거 (선택된 데이터만큼 제거)\n",
    "    unlabeled_data = unlabeled_data.drop(unlabeled_data.index[query_indices])\n",
    "\n",
    "    # 새로운 모델을 학습하여 계속 진행\n",
    "    initial_model = RandomForestRegressor()\n",
    "    initial_model.fit(X_labeled, Y_labeled)\n",
    "\n",
    "\n",
    "Y_pred = initial_model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE: 12.022497017761587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = \"./origin_data/test.csv\"\n",
    "test_data = pd.read_csv(test_csv).drop(columns=[\"id\", \"SMILES\"])\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "Y_test_pred = initial_model.predict(test_data)\n",
    "# predict\n",
    "df_submission = pd.read_csv(\"./origin_data/sample_submission.csv\")\n",
    "df_submission[\"MLM\"] = Y_test_pred[:,0]\n",
    "df_submission[\"HLM\"] = Y_test_pred[:,1]\n",
    "df_submission.to_csv(\"./submission/submission_SS35k_LBW.csv\", index = False, encoding = \"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "autog = pd.read_csv(\"./submission/autog.csv\")\n",
    "ss2 = pd.read_csv(\"./submission/submission_SS2_LBW.csv\")\n",
    "ss = pd.read_csv(\"./submission/submission_SS_LBW.csv\")\n",
    "ss35 = pd.read_csv(\"./submission/submission_SS35k_LBW.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
